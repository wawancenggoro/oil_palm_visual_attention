,notes,train_acc,train_loss,val_acc,val_loss
0,,0.35,0.4700,0.68,1.3023
1,,0.40,0.3133,0.72,1.0629
2,,0.41,0.2780,0.68,1.1488
3,,0.41,0.2772,0.70,1.1068
4,,0.42,0.2366,0.71,1.0807
5,,0.42,0.2404,0.66,1.8432
6,,0.43,0.2510,0.74,0.9970
7,,0.43,0.2347,0.63,1.6465
8,,0.43,0.2343,0.71,1.1978
9,,0.43,0.2425,0.68,1.4279
10,,0.43,0.2297,0.68,1.6291
11,,0.43,0.2474,0.63,1.5767
12,,0.44,0.2359,0.64,1.8969
13,,0.44,0.2277,0.73,1.3522
14,,0.44,0.2246,0.69,1.5619
15,created new Adam optimizer with LR: 0.00100000000000000002,0.44,0.2237,0.72,1.5861
16,,0.44,0.2413,0.75,1.7882
17,,0.45,0.1644,0.75,1.0520
18,,0.46,0.1427,0.74,1.0295
19,,0.46,0.1440,0.74,0.9648
20,,0.46,0.1386,0.75,1.0240
21,,0.45,0.1406,0.76,1.0300
22,,0.46,0.1286,0.76,0.9747
23,,0.46,0.1326,0.75,0.9659
24,,0.46,0.1280,0.76,0.9081
25,,0.46,0.1346,0.74,1.0102
26,,0.46,0.1285,0.75,0.9515
27,,0.46,0.1308,0.76,1.0099
28,,0.46,0.1291,0.75,0.9438
29,,0.46,0.1346,0.74,0.9456
30,,0.46,0.1283,0.74,0.9755
31,created new Adam optimizer with LR: 0.0001,0.46,0.1305,0.74,0.9890
32,,0.46,0.1294,0.75,0.9529
33,,0.46,0.1104,0.75,0.9563
34,,0.46,0.1169,0.75,0.9481
35,,0.46,0.1156,0.75,0.9523
36,,0.46,0.1177,0.76,0.9528
37,,0.46,0.1097,0.76,0.9725
38,,0.46,0.1202,0.76,0.9414
39,,0.46,0.1157,0.75,0.9434
40,,0.46,0.1235,0.76,0.9648
41,,0.46,0.1275,0.76,0.9433
42,,0.46,0.1117,0.76,0.9516
43,,0.46,0.1164,0.75,0.9362
44,,0.46,0.1202,0.75,0.9569
45,,0.46,0.1214,0.75,0.9578
46,,0.46,0.1151,0.74,0.9466
47,created new Adam optimizer with LR: 0.00001,0.46,0.1165,0.75,0.9571
48,,0.46,0.1190,0.75,0.9506
49,,0.46,0.1115,0.75,0.9510
50,,0.46,0.1184,0.75,0.9488
51,,0.46,0.1163,0.75,0.9480
52,,0.46,0.1149,0.75,0.9488
53,,0.46,0.1262,0.75,0.9482
54,,0.46,0.1157,0.75,0.9489
55,,0.46,0.1149,0.75,0.9505
56,,0.46,0.1158,0.75,0.9499
57,,0.46,0.1210,0.75,0.9471
58,,0.46,0.1172,0.75,0.9450
59,,0.46,0.1179,0.75,0.9440
60,,0.46,0.1207,0.75,0.9470
61,,0.46,0.1187,0.75,0.9487
62,,0.46,0.1159,0.75,0.9490
63,created new Adam optimizer with LR: 0.000001,0.46,0.1084,0.75,0.9491
64,,0.46,0.1140,0.75,0.9483
65,,0.46,0.1176,0.75,0.9483
66,,0.46,0.1171,0.75,0.9481
67,,0.46,0.1163,0.75,0.9484
68,,0.46,0.1243,0.75,0.9483
69,,0.46,0.1157,0.75,0.9481
70,,0.46,0.1171,0.75,0.9481
71,,0.46,0.1217,0.75,0.9484
72,,0.46,0.1193,0.75,0.9483
73,,0.46,0.1196,0.75,0.9483
74,,0.46,0.1121,0.75,0.9481
75,,0.46,0.1190,0.75,0.9481
76,,0.46,0.1159,0.75,0.9482
77,,0.46,0.1196,0.75,0.9483
78,,0.46,0.1209,0.75,0.9487
79,created new Adam optimizer with LR: 0.0000001,0.46,0.1184,0.75,0.9488
80,,0.46,0.1189,0.75,0.9488
81,,0.46,0.1228,0.75,0.9488
82,,0.46,0.1174,0.75,0.9488
83,,0.46,0.1180,0.75,0.9488
84,,0.46,0.1236,0.75,0.9488
85,,0.46,0.1143,0.75,0.9488
86,,0.46,0.1202,0.75,0.9488
87,,0.46,0.1166,0.75,0.9488
88,,0.46,0.1135,0.75,0.9488
89,,0.46,0.1206,0.75,0.9488
90,,0.46,0.1148,0.75,0.9488
91,,0.46,0.1171,0.75,0.9488
92,,0.46,0.1204,0.75,0.9487
93,,0.46,0.1149,0.75,0.9487
94,,0.46,0.1198,0.75,0.9487
95,created new Adam optimizer with LR: 0.00000001,0.46,0.1204,0.75,0.9487
96,,0.46,0.1199,0.75,0.9488
97,,0.46,0.1200,0.75,0.9488
98,,0.46,0.1153,0.75,0.9488
99,,0.46,0.1181,0.75,0.9488
